简易舆情监控与新闻聚合系统需求分析说明书
### 项目名称： mediasense

1. 引言

1.1 编写目的

在当今互联网普及率极高的背景下，社会上各式各样的新闻与言论传播速度显著加快，舆论环境也日趋复杂。为了让后续的设计与实现工作有明确的方向与依据，我们有必要对"简易舆情监控/新闻聚合系统"做一份全面、系统的需求分析。这份文档将对系统应实现的功能模块、性能要求、安全策略以及对外部服务（如 AI 接口）的调用方式做出细致说明。

此说明书的主要读者群包括项目管理人员、开发者及其他相关方。只有让大家对项目需求的方方面面都达成共识，才能尽量减少后期的重复劳动或重大变更，从而提高整体研发效率。

1.2 项目背景

随着移动设备以及各类社交应用的兴起，人们对资讯的获取渠道早已不仅限于传统媒体。各种新闻网站、微博话题、微信公众平台、自媒体专栏等纷纷涌现，使得海量的信息汇聚于网络之上。虽然这为公众的阅读与讨论带来了更多选择，但信息冗余和真实性难以甄别的问题也随之而来。加之存在部分虚假消息、过度炒作等乱象，普通用户往往很难在第一时间内获得具有完整视角的报道或正确观点。

面对这种状况，很多组织和个人都期望能有一款"简易而有效"的应用，不仅能聚合多家媒体的资讯供用户浏览，同时还具备对特定话题进行追踪和情感识别的能力，从而让使用者更好地洞察当前舆情走向或把握全貌。考虑到部署和运维成本，我们打算把所有关键的后端、前端、数据库及辅助服务统一放到同一台 Linux 服务器上运转，既满足项目在原型阶段的可行性需求，又能通过合理配置达到较好的性能。与此同时，鉴于人工智能技术的迅猛发展，我们计划和 OpenAI 提供的语言模型（诸如 GPT 系列）进行对接，力求在信息处理与情感分析层面拥有更好的智能化表现。

1.3 术语与名词解释

舆情监控：主要指收集并分析公众对某一主题或事件的言论内容，以识别潜在的风险和热点。  
新闻聚合：将来自不同平台或渠道的相关新闻进行整合和归类，便于读者在一个集中入口快速浏览多源报道。  
OpenAI：指提供人工智能模型接口的第三方平台，能够执行深度文本分析、情感判断、对话生成等多种语言任务。  
Linux 服务器：即本系统所依托的运行环境，用于布置所有功能模块，包括后端 API、数据库、爬虫调度等部分。



2. 项目前景与需求范围

2.1 国内外研究现状与可行性

当代舆情分析在许多国家已受到高度关注。一些国际化公司在大数据与云计算的基础上构建了相对完善的解决方案，包括多语言文本挖掘、实时热点追踪以及可视化呈现等。国内的大型互联网企业和政府部门也陆续推出自研或合作性质的舆情监控系统，为公关处理、风险预警以及社会治理等方面提供支撑。不过，对于中小型机构或者个人用户而言，专业性的高端系统往往造价不菲，也可能在功能上过于庞大，导致学习成本较高。

因此，利用开源工具与轻量化思路，搭建一款简单可扩展的新闻聚合与舆情监控应用，具有现实意义。再加上人工智能的日益成熟，通过将一些语义分析或情感计算部分接入远程 AI 模型，就能够降低自行训练模型或购买高性能硬件的门槛，为本项目提供可行且经济的路径。

2.2 项目定位及用户群体

1. 公众机构与企事业单位：他们可能需要及时掌握社会对某个政策、事件或品牌的反应，以便做出合理应对或进行形象管理。  
2. 媒体从业人员：快速聚合多家媒体报道，能够帮助编辑或记者从多角度了解一个新闻事件，避免盲区或遗漏。  
3. 研究人员：学术界或市场调研领域对于话题演化、公共情绪走势等有着相当兴趣，可以把本系统当作一个数据采集及初步分析平台。  
4. 普通个人用户：在大数据时代若能有一款简易且灵活的聚合阅读工具，也能节省他们在不同网站之间跳转的时间，并通过情感识别功能对一些争议事件有更直观的判断。

2.3 系统需求总体范围

多源数据采集：包括常见新闻门户、部分社交网站以及可能的 RSS 源，用于获取多样的文本信息。  
文本预处理：包括去重、分词等基础文本处理。  
聚合与可视化：一站式呈现来自不同来源的报道与评论，并通过图形界面对舆情数据进行多维度分析。  
部署方式：以单台 Linux 服务器为主，方便在初期进行模块整合。



3. 系统总体功能需求

3.1 功能模块

1. 爬虫模块  
   设置定时或触发式抓取，针对指定 URL 或平台进行数据收集。  
   通过配置文件或管理界面对爬取目标进行维护，方便修改抓取规则。  

2. 文本处理模块  
   负责分词、停用词过滤、文本去重等基础处理。  

3. 新闻聚合与检索模块  
   基于分类、关键词或发布时间等多个维度呈现聚合后的新闻列表。  
   用户可输入检索关键词，系统从索引中快速匹配与之相关的报道或评论，并提供基于热度的排序选项。  

4. 可视化展示模块  
   借助饼图、词云、趋势图等，直观地显示话题热度及数据演变情况。  
   支持用户在图表中进行交互式筛选或查看详细信息。  

5. 用户管理与权限模块  
   主要区分管理员与普通访客的使用权限。管理员可配置系统参数及采集规则，而访客或普通用户只能进行阅读、搜索或查看部分分析结果。  

3.2 关键用例说明

用例：添加新采集源  
  管理员登录到系统后台，选择"新增数据源"并填写网站链接及爬取频率。系统在下一次调度时便会自动抓取新网址所对应的内容。若该源出现结构变化或防爬手段增强，管理员可随时更新配置。  

用例：新闻搜索与查看  
  用户在前端输入搜索条件，如关键词"某品牌名称"，系统在数据库或索引引擎中查询对应文本，并且按照时间、权威度等维度进行排序，然后返回列表让用户查看详情。  

3.3 用户角色与权限

管理员：可执行配置变更、查看日志报表、管理爬虫目标等。  
普通登录用户：除可以搜索与阅读信息外，也可查看有限的图表和情感分析结果。若系统支持评论或收藏功能，则在登录状态下才能使用此类功能。  
访客：无需登录即可访问首页或公共数据，但高级功能和敏感数据被隐藏。  



4. 系统非功能需求

4.1 性能需求

响应速度  
  普通查询最好能在一秒内返回结果，若是对大批量文本进行 AI 分析，可能需要几秒到几十秒的时间，此时可在前端进行加载动画或进度提示。  

4.2 安全需求

访问权限  
  管理员操作界面采用 JWT（JSON Web Token）进行身份认证与权限控制，确保敏感配置的安全。
  用户密码经过加密后存储，避免明文泄露风险。
数据保护  
  对数据库中存储的关键字段（例如 OpenAI 的 API Key）应进行加密或仅放在环境变量中，并通过 HTTPS 方式进行网络传输。  

4.3 可用性与兼容性

易用性  
  系统前端应配合通俗易懂的操作指引与搜索栏设计，让并非技术背景的用户也能轻松检索新闻与查看分析结果。  
兼容性  
  前端页面只需兼容主流桌面浏览器，对于移动端视图可暂时不做过多优化。后端在 Linux 环境下运行即可满足本项目需求。  

4.4 可维护性与可扩展性

日志监控与维护  
  爬虫任务及 AI 分析调用都需要详细的日志记录，便于查看调用频次、是否被封以及任务执行情况。若出现爬虫失效或者 OpenAI 服务超时，可在日志中迅速定位并采取措施。  



5. 系统数据需求

5.1 数据来源与采集流程

数据源  
  首批定位于几家公众媒体网站、常见门户的 RSS 以及部分活跃的社交账号。根据实际需求，也可以在后期加入更多新闻或微博话题链接进行抓取。  
采集策略  
  默认采用定时爬虫方式，每隔一定时间轮询目标网站。若发生重大突发事件，也允许手动触发即时采集，加快更新速度。  

防爬虫机制应对：  
很多网站会启用各种手段阻拦自动采集，如封 IP、要求验证码、动态加载数据等。我们可以采用下列措施加以应对：  
1. 限制访问频率：在爬虫调度端设置抓取间隔和并发数量，尽量模拟正常用户行为，降低对方的警惕。  
2. 优先使用 RSS：如果目标网站提供 RSS 订阅，那么先从 RSS 获取数据会更安全也更高效。  
3. 必要时识别验证码：对于必须要破解验证码的场景，可考虑由管理员手动辅助。  
4. 动态渲染：对于采取大量 JavaScript 渲染的站点，可以用 Puppeteer 之类的技术让爬虫"真机模拟"，但必须注意资源消耗与执行效率。  

5.2 数据结构与存储

字段示例  
  标题、链接、来源、作者、正文摘要、完整正文、发布时间、关键词列表、爬取时间等。  
  
已实现的扩展字段：
  - 新闻表自动更新时间戳（update_time）

数据库或索引  
  采用 MySQL 8.0+ 作为主数据库，使用 InnoDB 引擎确保事务安全，后期可根据需求引入 Elasticsearch 做全文检索加速。

5.3 数据处理与可视化

分词与降噪  
  采用中文分词库处理正文，去除常见停用词以及广告、HTML 残片等无效内容，以便后续分析。  
可视化  
  绘制包含话题热度趋势、情感占比饼图、关键词词云等。用户可以查看实时或最近几日的数据变化。



6. 技术实现与部署方案

6.1 技术选型

开发语言  
  后端采用 Python 3.12 + Django 4.2.0 实现爬虫逻辑与业务接口，前端采用 Vue 搭建单页应用。  
数据库  
  采用 MySQL 8.0+ 作为主数据库，后期可根据需求考虑引入 Elasticsearch 做全文检索。  

6.2 系统核心模块

1. **数据库设计**
   - 用户认证表设计完成
   - 新闻内容表设计完成
   - 爬虫配置表设计完成
   - AI分析结果表设计完成
   - 搜索建议表设计完成
   - 系统监控表设计完成

2. **用户认证系统** (`auth/`)
   - 支持用户注册与登录
   - 实现基于角色的权限控制
   - 管理员账户配置完成
   - JWT 认证机制实现
   - 密码加密存储
   - 会话管理
   - 密码重置功能

3. **新闻管理模块** (`news/`)
   - 新闻内容管理
   - 新闻分类管理
   - 新闻元数据管理
   - 新闻导入导出
   - 新闻状态管理
   - 新闻审核流程

4. **搜索服务** (`news_search/`)
   - 新闻全文检索
   - 多维度新闻聚合
   - 基于时间的排序
   - 热点新闻缓存
   - ElasticSearch集成
   - 搜索建议功能
   - 高级过滤功能

5. **爬虫系统** (`crawler/`)
   - 提供管理界面配置和启动定时抓取
   - 支持 RSS 和网页抓取
   - 动态页面渲染支持
   - 代理池管理
   - 反爬策略
   - 数据清洗
   - 自动化调度

6. **AI服务** (`ai_service/`)
   - 文本分析和预处理
   - 新闻情感分析
   - 关键词提取
   - 新闻摘要生成
   - OpenAI接口集成
   - 模型版本管理
   - 分析结果缓存

7. **系统监控** (`monitoring/`)
   - 系统资源监控
   - 服务状态监控
   - 基础性能监控
   - 告警配置
   - 监控数据可视化
   - 系统日志分析
   - 性能瓶颈分析

8. **API模块** (`api_v1/`)
   - RESTful API实现 ✓
   - 接口权限控制 ✓
   - 接口版本管理 ✓
   - 接口文档自动生成 ✓
   - 速率限制 ✓
   - 响应格式标准化 ✓
   - API路由统一管理 ✓
   - OpenAPI Schema支持 ✓

9. **配置管理** (`config/`)
   - 系统配置管理
   - 环境变量管理
   - 服务配置管理
   - 部署配置
   - 安全配置
   - 缓存配置

10. **日志系统** (`logs/`)
    - 操作日志记录
    - 错误日志分析
    - 日志文件管理
    - 日志轮转策略
    - 错误追踪
    - 审计日志


6.3 运行环境与接口需求

Linux 单机部署  
  系统整体在一台服务器上跑，包括后端服务、数据库进程与前端静态资源托管。要保证服务器对外网的访问通畅，否则 AI 调用无法完成。  
接口形式  
  一般会采用 RESTful 风格，也可以考虑用 GraphQL 方便前端做复杂查询。  
OpenAI 调用  
  需在后端保存好密钥，不可泄露给前端 JavaScript；并注意计费和速率限制，避免过度调用造成经济负担。



7. 需求阶段的进度安排

7.1 需求评审与修改

在完成本说明书的初稿后，应尽快与相关干系人（包括导师、团队管理者等）沟通，以确认需求目标是否与现实吻合。若在后续遇到新情况或技术困难，应有一套需求变更机制，比如由核心小组讨论通过后再更新文档、修正版本号等，从而保持系统开发的稳定性和连贯性。

7.2 版本管理与后续规划

每当需求出现大的增减或调整，都应该更新文档版本并进行变更记录，以便随时查看前后差异。本需求说明书与后续的系统设计、用户手册等文档也要相互对应，形成完整的项目文档集。